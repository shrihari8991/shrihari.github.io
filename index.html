<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
		<meta name="description" content="" />
		<meta name="author" content="" />
		<title>Underwater Object Detection</title>
		<link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
		<!-- Font Awesome icons (free version)-->
		<script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
		<!-- Google fonts-->
		<link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
		<link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
		<!-- Core theme CSS (includes Bootstrap)-->
		<link href="css/styles.css" rel="stylesheet" />
	</head>
	<body id="page-top">
		<!-- Navigation-->
		<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
			<a class="navbar-brand js-scroll-trigger" href="#page-top">
				<span class="d-block d-lg-none">Shrihari A</span>
				<span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpg" alt="..." /></span>
			</a>
			<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
			<div class="collapse navbar-collapse" id="navbarResponsive">
				<ul class="navbar-nav">
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research</a></li>
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>
					<li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
				</ul>
			</div>
		</nav>
		<!-- Page Content-->
		<div class="container-fluid p-0">
			<!-- About-->
			<section class="resume-section" id="about">
				<div class="resume-section-content">
					<h1 class="mb-0">Shrihari<span class="text-primary">A</span></h1>
					<div class="subheading mb-5">
						Centre for Intelligent Cyber-Physical Systems, Indian Institute of Technology Guwahati, North Guwahati - 781039
						<a href="mailto:a.shrihari@iitg.ac.in">a.shrihari@iitg.ac.in</a>
					</div>
					<p class="lead mb-5">I am a Ph.D scholar at IIT Guwahati working on Underwater Object Detection. I am excited about complex problems that can be tackled with learning-based systems using deep neural networks. Currently, my research focuses on Underwater Object Detection, and I am interseted in knowing how well an object can be detected in challenging environments.</p>
					<div class="social-icons">
						<a class="social-icon" href="https://www.linkedin.com/in/shrihari-a-35bb1915"><i class="fab fa-linkedin-in"></i></a>
						<a class="social-icon" href="https://www.github.com/shrihari8991"><i class="fab fa-github"></i></a>
						<!-- <a class="social-icon" href="#!"><i class="fab fa-twitter"></i></a> -->
						<!-- <a class="social-icon" href="#!"><i class="fab fa-facebook-f"></i></a> -->
					</div>
				</div>
			</section>
			<hr class="m-0" />
			<!-- Research -->
			<section class="resume-section" id="research">
				<div class="resume-section-content">
					<h2 class="mb-5">Research</h2>
					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
						<div class="flex-grow-1">
							<h3 class="mb-0">Underwater Object Detection</h3>
							<div class="subheading mb-3">Divers, Submarines, ROVs, Shipwrecks, etc...</div>

							<p>Remotely Operated Vehicles (ROVs) along with vision based underwater object detection techniques can assist underwater exploration
and research by identifying specific objects, such as shipwrecks, marine life, and man-made debris. These object detection algorithms require large datasets for training. Since there are very few datasets available for underwater objects, in this paper, an Extended Underwater Object Detection dataset with 16 object categories (EUWOD-16) was constructed. This was achieved by building a new annotated dataset consisting of divers, artifacts and various marine species, and merging it with existing underwater object detection datasets by redefining their annotations. Later, the dataset was evaluated by a modified YOLOv5n architecture with GhostNet. This method involved the selective additions of ghost blocks in appropriate places to decrease the number of network parameters and FLOPs without a significant decrease in performance, and a Bi-FPN connection for a refined feature fusion pathway. The proposed model achieved higher accuracy at a comparatively lower number of parameters (and FLOPs) than both YOLOv5n and GhostNet.</p>
							
							<p>The tasks of underwater exploration, marine ecosystem study, seafloor mapping, historical wreck or artifact investigation, and underwater surveillance provide crucial insights into defense/military purposes for intrusion detection and target identification. It also helps in understanding the impacts of human activities on the oceans over time. This would help in developing effective strategies for Naval Forces.</p>
							<p>Underwater object detection is challenging due to the factors such as low visibility, high noise, and color deviation, which could make it difficult to identify and track objects [7]. Another set of challenges includes the requirement of accurate and stable detection models that could operate under resource constraints in real time. This is because underwater environments often have limited computational resources and data transmission capabilities. In addition to the aforementioned factors, the diversity and comprehensiveness of datasets are also crucial in building robust object detection models. The ability of the model to accurately classify a wide range of objects in practical scenarios is largely dependent on the diversity and number of classes present in the dataset. The existing datasets for underwater object detection mostly consist of aquatic creatures such as fish, echinus, holothurians, starfish, and scallops.</p>
							<img src="assets/img/Introduction.png" class="img-fluid" alt="Introduction" />
							
							<p>A new dataset named UDAD is been proposed to include divers, underwater artifacts, fish, and other marine species. Also, several existing datasets such as DUO, UODD, Trash-ICRA19 and the Brackish Dataset have been merged with the proposed UDAD dataset to provide a diverse range of objects and underwater environments, forming a comprehensive dataset EUOD16. This dataset contains five distinct classes: ROV, artifact, diver, fish, and other-bio. The dataset comprises a total of 2,697 images collected from three different sources: The first source is the UIEB, an image enhancement dataset, which consists of 890 images depicting various scenes with statues, shipwrecks, and divers. However, only 671 images were selected out of that dataset, and remaining images with many clustered fishes were ignored, since the focus is on divers and artifacts. The second source is the SUIM, an underwater segmentation dataset, which contains 1,525 train and 110 test images with segmentation labels. From this dataset, total 1,533 images were selected and over-crowded fish images were discarded. The third source is a YouTube video from the channel Guillaume Nery, from which 493 frames were generated and selected where a diver was thoroughly or appropriately present. All the selected images are annotated using labelImg software, resulting in a total of 2,697 annotated images. The existing datasets were merged by refining the labels to form the combined dataset. Then the combined dataset is extended with the UDAD dataset to form EUOD16 (Extended Underwater Object Detection) with 16 different classes.</p>
							<img src="assets/img/Proposed_Dataset.png" class="img-fluid" alt="Proposed Dataset" />
							
							<p>A modified YOLO-v5n (nano) model has been proposed. The proposed model, termed as YOLOv5-CSGB (Selective Ghosted Convolution with Bi- FPN), consists of GhostNet convolutions and Bi-FPN connection for creating more feature maps with less parameters and aggregating contextual information from multiple levels of the feature pyramid, respectively. The backbone of the YOLOv5 model is CSPDarknet-53, which is made up of repeating blocks of Cross Stage Partial Network (CSP) bottleneck, C3 layers and normal convolution layers. GhostNet is a cost-effective alternative to traditional convolutional blocks, characterized by a reduction in both the number of weights and floating-point operations (FLOPs). It has been demonstrated that traditional convolutions generate a significant amount of redundancy in the feature maps. Hence, this method advocates for the generation of only a certain percentage of feature maps via traditional convolution blocks, while the rest are generated via inexpensive linear operations, aided by Depthwise convolutions. Instead of converting all normal convolutions to Ghost modules, only specific convolutions were converted, called Selective Ghosting. Channel Sharpening Attention Module (CSAM) is a channel-wise attention mechanism introduced to enhance the expressiveness of the YOLOv5 model in object detection tasks, particularly in challenging underwater environments where stacking, blurring, and unclear edges can occur between objects due to the opacity of the water and shooting angles. Bidirectional Feature Pyramid Network (Bi-FPN) is a feature fusion method that combines multi-scale features from different levels of the backbone and neck of the model. So, the proposed model YOLOv5-CSGB uses selective ghosting to get higher number of feature without increasing model size and uses BiFPN for improving multi-scale detection capability and CSAM to improve the sharpness of the images at the input.</p>
							<img src="assets/img/yolov5_CSGB.png" class="img-fluid" alt="Methods" />
							<img src="assets/img/c3.png" class="img-fluid" alt="Methods" />
							<img src="assets/img/ghostconv.png" class="img-fluid" alt="Methods" />
							<img src="assets/img/ghostc3.png" class="img-fluid" alt="Methods" />

							<p>The system used for the conducted experiments has linux operating System with NVIDIA Tesla V100 32GB memory with CUDA 10.2. The programming language and framework used are python 3.9 and pytorch 1.8.0 respectively. All the models during the experiments were trained with batch size 8 and the learning rate starting at 0.01 for 200 epochs with SGD Optimizer. Quantitative analysis was performed and compared with the existing YOLOv5n and GhostNet models. The YOLOv5-CSGB achieves 4.1% increase in mAP@0.5-0.95 metrics in the EUOD16 dataset and 11.8%, 13%, and 7.9% increase in mAP@0.5-0.95 in the classes divers, artifact, and ROVs, respectively.</p>
							<img src="assets/img/quality.png" class="img-fluid img-thumbnail" alt="Results" />
							<img src="assets/img/PR_curve.jpg" class="img-fluid img-thumbnail" alt="Results" />
						</div>
						<!-- <div class="flex-shrink-0"><span class="text-primary">March 2013 - Present</span></div> -->
					</div>
				</div>
			</section>
			<!-- Publications-->
			<section class="resume-section" id="publications">
				<div class="resume-section-content">
					<h2 class="mb-5">Publications</h2>
					<div class="d-flex flex-column flex-md-row justify-content-between mb-5">
						<div style="margin-bottom: 3em;"> 
							<div class="row">
								<div class="col-sm-3">
									<img src="assets/img/planktons.jpg" class="img-fluid img-thumbnail" alt="Project image">
								</div>
								<div class="col-sm-9">
									<a target="_blank">A Novel Network Architecture for Microplankton Classification in Digital Holographic Images</a>
									<br><span style="font-weight: bold";>Shrihari A</span>, 
									<a href="https://orcid.org/0000−0003−2885−0026" target="_blank">Prithwijit Guha</a>, 
									<a href="https://orcid.org/0000−0001−7509−9269" target="_blank">Rishikesh Kulkarni</a>, 
									<br><span style="font-style: italic;">arXiv.org</span>, 2023 
									<br><a href="https://github.com/shrihari8991" target="_blank">Project Page</a> / 
									<a href="#!" target="_blank">Paper</a> /
									<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseShrihari2023ARXIV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
									<div class="collapse" id="collapseShrihari2023ARXIV">
										<div class="card card-body">
											<pre><code>
												@InProceedings{Shrihari2023ARXIV, author = {Shrihari A and Prithwijit Guha and Rishikesk Kulkarni}, title = {A Novel Network Architecture for Microplankton Classification in Digital Holographic Images}, conference = {10th International Conference on Pattern Recognition and Machine Intelligence}, publisher = {Springer}, year = {2023}}
											</code></pre>
										</div>
									</div> 
								</div> 
								<div class="col-sm-3">
									<img src="assets/img/planktons.jpg" class="img-fluid img-thumbnail" alt="Project image">
								</div>
								<div class="col-sm-9">
									<a target="_blank">A Novel Network Architecture for Microplankton Classification in Digital Holographic Images</a>
									<br><span style="font-weight: bold";>Shrihari A</span>, 
									<a href="https://orcid.org/0000−0003−2885−0026" target="_blank">Prithwijit Guha</a>, 
									<a href="https://orcid.org/0000−0001−7509−9269" target="_blank">Rishikesh Kulkarni</a>, 
									<br><span style="font-style: italic;">arXiv.org</span>, 2023 
									<br><a href="https://shrihari.github.io" target="_blank">Project Page</a> / 
									<a href="#!" target="_blank">Paper</a> /
									<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseShrihari2023ARXIV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
									<div class="collapse" id="collapseShrihari2023ARXIV">
										<div class="card card-body">
											<pre><code>@InProceedings{Shrihari2023ARXIV, 
												author = {Shrihari A and Prithwijit Guha and Rishikesk Kulkarni}, 
												title = {A Novel Network Architecture for Microplankton Classification in Digital Holographic Images}, 
												conference = {10th International Conference on Pattern Recognition and Machine Intelligence},
												publisher = {Springer},
												year = {2023}
												}
											</code></pre>
										</div>
									</div> 
								</div>
								<div class="col-sm-3">
									<img src="assets/img/planktons.jpg" class="img-fluid img-thumbnail" alt="Project image">
								</div>
								<div class="col-sm-9">
									<a target="_blank">A Novel Network Architecture for Microplankton Classification in Digital Holographic Images</a>
									<br><span style="font-weight: bold";>Shrihari A</span>, 
									<a href="https://orcid.org/0000−0003−2885−0026" target="_blank">Prithwijit Guha</a>, 
									<a href="https://orcid.org/0000−0001−7509−9269" target="_blank">Rishikesh Kulkarni</a>, 
									<br><span style="font-style: italic;">arXiv.org</span>, 2023 
									<br><a href="https://shrihari.github.io" target="_blank">Project Page</a> / 
									<a href="#!" target="_blank">Paper</a> /
									<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseShrihari2023ARXIV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
									<div class="collapse" id="collapseShrihari2023ARXIV">
										<div class="card card-body">
											<pre><code>@InProceedings{Shrihari2023ARXIV, 
												author = {Shrihari A and Prithwijit Guha and Rishikesk Kulkarni}, 
												title = {A Novel Network Architecture for Microplankton Classification in Digital Holographic Images}, 
												conference = {10th International Conference on Pattern Recognition and Machine Intelligence},
												publisher = {Springer},
												year = {2023}
												}
											</code></pre>
										</div>
									</div> 
								</div>
							</div> 
						</div>
					</div>
				</div>
			</section>
			<!-- Skills-->
			<section class="resume-section" id="skills">
				<div class="resume-section-content">
					<h2 class="mb-5">Skills</h2>
					<div class="subheading mb-3">Programming Languages & Tools</div>
					<ul class="list-inline dev-icons">
						<!--<li class="list-inline-item"><i class="fab fa-python"></i></li>-->
						<!--<li class="list-inline-item"><img src="assets/img/python.png" alt="python" /></li>-->
						<li class="list-inline-item"><img src="assets/img/python.png" alt="python" width="200px" height="100px" /></li>
						<li class="list-inline-item"><img src="assets/img/keras.png" alt="keras" width="200px" height="100px" /></li>
						<li class="list-inline-item"><img src="assets/img/tensorflow.svg" alt="tensorflow" width="200px" height="100px" /></li>
						<li class="list-inline-item"><img src="assets/img/pytorch.svg" alt="pytorch" width="200px" height="100px" />PyTorch</li>
						<li class="list-inline-item"><img src="assets/img/pyspark.png" alt="pyspark" width="200px" height="100px" />PySPARK</li>
						<li class="list-inline-item"><img src="assets/img/matlab.svg" alt="matlab" width="200px" height="100px" /></li>
						<li class="list-inline-item"><img src="assets/img/r_pgm.png" alt="r_program" width="200px" height="100px" /></li>
						<li class="list-inline-item"><img src="assets/img/hadoop.jpg" alt="hadoop" width="200px" height="100px" /></li>
					</ul>
					<div class="subheading mb-3">Workflow</div>
					<ul class="fa-ul mb-0">
						<li>
							<span class="fa-li"><i class="fas fa-check"></i></span>Deep Learning and Machine Learning
						</li>
						<li><span class="fa-li"><i class="fas fa-check"></i></span>Computer Vision</li>
						<li><span class="fa-li"><i class="fas fa-check"></i></span>Distributed Computing</li>
					</ul>
				</div>
			</section>
			<hr class="m-0" />
			<!-- Interests-->
			<section class="resume-section" id="interests">
				<div class="resume-section-content">
					<h2 class="mb-5">Interests</h2>
					<p>Apart from being a researcher, I enjoy most of my free time getting updated with the recent technologies in the field of deep learning. I enjoy trecking, travelling and exploring places.</p>
					<p class="mb-0">When forced indoors, I spend a large amount of my free time exploring the spiritual aspect of life.</p>
				</div>
			</section>
			<hr class="m-0" />
			<!-- Awards-->
			<section class="resume-section" id="awards">
				<div class="resume-section-content">
					<h2 class="mb-5">Awards & Certifications</h2>
					<ul class="fa-ul mb-0">
						<li>
							<span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
							Accelerated Data Science Course Completion
						</li>
						<li>
							<span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
							Guest speaker at 10 day summer workshop on "machine learning and deep learning"
						</li>
					</ul>
				</div>
			</section>
		</div>
		<!-- Bootstrap core JS-->
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
		<!-- Core theme JS-->
		<script src="js/scripts.js"></script>
	</body>
</html>
